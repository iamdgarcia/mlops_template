name: MLOps Pipeline

on:
  push:
    branches: [ main, master, develop ]
  pull_request:
    branches: [ main, master ]
  schedule:
    # Run drift detection daily at 2 AM UTC
    - cron: '0 2 * * *'

env:
  PYTHON_VERSION: '3.11'
  MLFLOW_TRACKING_URI: sqlite:///mlruns.db

jobs:
  security-scan:
    name: Security Vulnerability Scanning
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        cache: 'pip'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install safety bandit
    
    - name: Run Safety check for dependency vulnerabilities
      run: |
        safety check --json || echo "Safety check completed with warnings"
    
    - name: Run Bandit security linter
      run: |
        bandit -r src/ -f json -o bandit-report.json || true
        bandit -r src/ -ll -f screen
    
    - name: Upload security reports
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: security-reports
        path: |
          bandit-report.json
        retention-days: 30

  code-quality:
    name: Code Quality Checks
    runs-on: ubuntu-latest
    needs: security-scan
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        cache: 'pip'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install -r requirements-dev.txt
    
    - name: Check code formatting with black
      run: |
        black --check --diff src/ tests/ scripts/
    
    - name: Check import sorting with isort
      run: |
        isort --check-only --diff src/ tests/ scripts/
    
    - name: Lint with flake8
      run: |
        # Stop the build if there are Python syntax errors or undefined names
        flake8 src/ tests/ scripts/ --count --select=E9,F63,F7,F82 --show-source --statistics
        # Exit-zero treats all errors as warnings
        flake8 src/ tests/ scripts/ --count --exit-zero --max-complexity=10 --max-line-length=127 --statistics

  unit-tests:
    name: Unit and Integration Tests
    runs-on: ubuntu-latest
    needs: code-quality
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        cache: 'pip'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install -r requirements-dev.txt
    
    - name: Run unit tests with coverage
      run: |
        pytest tests/ -v --cov=src --cov-report=xml --cov-report=term-missing
    
    - name: Upload coverage reports
      uses: codecov/codecov-action@v3
      with:
        file: ./coverage.xml
        flags: unittests
        name: codecov-umbrella
        fail_ci_if_error: false

  data-pipeline-validation:
    name: Data Pipeline Validation
    runs-on: ubuntu-latest
    needs: unit-tests
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        cache: 'pip'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    
    - name: Create necessary directories
      run: |
        mkdir -p data models logs mlruns
    
    - name: Run full data pipeline
      run: |
        python scripts/run_data_pipeline.py
    
    - name: Validate pipeline outputs
      run: |
        # Check that required data files were created
        test -f data/transactions_raw.csv || exit 1
        test -f data/transactions_processed.csv || exit 1
        test -f data/transactions_final.csv || exit 1
        echo "‚úì All required data files created"
    
    - name: Upload pipeline artifacts
      uses: actions/upload-artifact@v4
      with:
        name: pipeline-outputs
        path: |
          data/*.csv
          data/*.json
        retention-days: 7

  model-training:
    name: Model Training and Registration
    runs-on: ubuntu-latest
    needs: data-pipeline-validation
    if: github.event_name == 'push' && (github.ref == 'refs/heads/main' || github.ref == 'refs/heads/master')
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        cache: 'pip'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    
    - name: Download pipeline artifacts
      uses: actions/download-artifact@v4
      with:
        name: pipeline-outputs
    
    - name: Create necessary directories
      run: |
        mkdir -p mlruns models logs
    
    - name: Train and register models
      run: |
        python scripts/run_training.py
    
    - name: Validate deployment package
      run: |
        python scripts/validate_deployment.py
    
    - name: Upload trained model artifacts
      uses: actions/upload-artifact@v4
      with:
        name: trained-models
        path: |
          models/*.joblib
          data/selected_features.json
          data/training_summary.json
        retention-days: 30
    
    - name: Upload deployment package
      uses: actions/upload-artifact@v4
      with:
        name: deployment-package
        path: |
          models/*.joblib
          data/selected_features.json
          configs/
          src/
          requirements.txt
          scripts/serve_model.py
          scripts/validate_deployment.py
        retention-days: 30

  deploy-staging:
    name: Deploy to Staging
    runs-on: ubuntu-latest
    needs: [model-training]
    if: github.event_name == 'push' && (github.ref == 'refs/heads/main' || github.ref == 'refs/heads/master')
    environment:
      name: staging
      url: https://staging-fraud-detection.example.com
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
    
    - name: Download deployment package
      uses: actions/download-artifact@v4
      with:
        name: deployment-package
    
    - name: Verify deployment artifacts
      run: |
        python scripts/validate_deployment.py
    
    - name: Deploy to staging environment
      run: |
        echo "üöÄ Deploying to staging environment"
        echo "‚úì Model artifacts verified"
        echo "‚úì Configuration validated"
        # Add your actual deployment commands here
        # Examples for Google Cloud Run:
        # gcloud run deploy fraud-detection-staging \
        #   --source . \
        #   --region us-central1 \
        #   --platform managed \
        #   --allow-unauthenticated \
        #   --set-env-vars ENVIRONMENT=staging
    
    - name: Run health check
      run: |
        echo "üè• Running health checks on staging deployment"
        # Add health check commands
        # curl -f https://staging-fraud-detection.example.com/health || exit 1
        # curl -f https://staging-fraud-detection.example.com/model/info || exit 1

  deploy-production:
    name: Deploy to Production
    runs-on: ubuntu-latest
    needs: deploy-staging
    if: github.event_name == 'push' && (github.ref == 'refs/heads/main' || github.ref == 'refs/heads/master')
    environment:
      name: production
      url: https://fraud-detection.example.com
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
    
    - name: Download deployment package
      uses: actions/download-artifact@v4
      with:
        name: deployment-package
    
    - name: Verify deployment artifacts
      run: |
        python scripts/validate_deployment.py
    
    - name: Deploy to production environment
      run: |
        echo "üöÄ Deploying to production environment"
        echo "‚úì Model artifacts verified"
        echo "‚úì Configuration validated"
        # Add your actual production deployment commands here
        # Examples for Google Cloud Run:
        # gcloud run deploy fraud-detection-prod \
        #   --source . \
        #   --region us-central1 \
        #   --platform managed \
        #   --allow-unauthenticated \
        #   --set-env-vars ENVIRONMENT=production \
        #   --min-instances 1 \
        #   --max-instances 10
    
    - name: Run production health check
      run: |
        echo "üè• Running health checks on production deployment"
        # Add health check commands
        # curl -f https://fraud-detection.example.com/health || exit 1
        # curl -f https://fraud-detection.example.com/model/info || exit 1
    
    - name: Notify deployment
      run: |
        echo "üì¢ Production deployment complete"
        # Add notification logic (Slack, email, etc.)
        # Example: Send to Slack webhook
        # curl -X POST -H 'Content-type: application/json' \
        #   --data '{"text":"Fraud Detection Model deployed to production"}' \
        #   $SLACK_WEBHOOK_URL

  drift-detection:
    name: Drift Detection Monitoring
    runs-on: ubuntu-latest
    if: github.event_name == 'schedule'
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        cache: 'pip'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    
    - name: Run drift detection
      run: |
        echo "Running scheduled drift detection"
        python -c '
        from src.drift_detection import DriftDetector
        import pandas as pd
        import json
        from datetime import datetime
        
        # Load reference and current data
        reference_data = pd.read_csv("data/transactions_final.csv")
        # In production, load recent production data here
        current_data = reference_data.sample(n=1000, random_state=42)
        
        # Run drift detection
        with open("data/selected_features.json", "r") as f:
            feature_info = json.load(f)
            selected_features = feature_info.get("features", [])
        
        detector = DriftDetector(reference_data, selected_features)
        drift_results = {}
        
        for feature in selected_features[:5]:  # Check top 5 features
            result = detector.detect_feature_drift(current_data, feature)
            drift_results[feature] = result
            if result["drift_detected"]:
                print(f"WARNING: Drift detected in {feature}: p-value={result[\"p_value\"]:.4f}")
        
        print(f"Drift detection complete. Checked {len(drift_results)} features.")
        '
    
    - name: Create drift alert
      if: failure()
      run: |
        echo "Critical drift detected - creating alert"
        # Add alerting logic (PagerDuty, Slack, email, etc.)