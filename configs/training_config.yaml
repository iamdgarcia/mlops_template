# Training Configuration for Fraud Detection Model

# Data Configuration
data:
  raw_data_path: "data/raw/transactions.csv"
  processed_data_path: "data/processed/"
  test_size: 0.2
  validation_size: 0.2
  random_state: 42
  
  # Data generation parameters (reduced for quick demos)
  n_samples: 20000
  fraud_rate: 0.02  # 2% fraud rate (realistic)
  
# Feature Engineering
features:
  categorical_features:
    - "merchant_category"
    - "transaction_type"
    - "device_type"
  
  numerical_features:
    - "amount"
    - "hour_of_day"
    - "day_of_week"
    - "user_transaction_frequency"
    - "user_avg_amount"
    - "amount_zscore"
  
  target_column: "is_fraud"
  
  # Feature engineering parameters
  lookback_days: 30  # Days to look back for user behavior features
  min_user_transactions: 5  # Minimum transactions for user features

# Model Training Configuration
models:
  output_dir: "models"

  logistic_regression:
    enabled: true
    hyperparameters:
      C: [0.1, 1.0]
      max_iter: [500]
      class_weight: ["balanced"]
      solver: ["liblinear"]
    
  # Keep disabled for faster runs in the intro path; enable later if desired
  xgboost:
    enabled: false
    hyperparameters:
      n_estimators: [100]
      max_depth: [3]
      learning_rate: [0.1]
      scale_pos_weight: [1]

  # Optional: allow overriding RandomForest grid in trainer fallback
  random_forest:
    enabled: true
    hyperparameters:
      n_estimators: [100]
      max_depth: [5, null]
      min_samples_split: [2]
      min_samples_leaf: [1]

# Cross-validation
cross_validation:
  cv_folds: 3
  scoring: "roc_auc"
  n_jobs: -1

# MLflow Configuration
mlflow:
  experiment_name: "fraud-detection"
  tracking_uri: "file:./mlruns"
  model_name: "fraud-detector"
  
  # Autolog settings
  autolog:
    log_input_examples: true
    log_model_signatures: true
    log_models: true

# Model Evaluation
evaluation:
  metrics:
    - "accuracy"
    - "precision"
    - "recall"
    - "f1_score"
    - "roc_auc"
    - "average_precision"
  
  # Thresholds for model acceptance
  # Note: These are realistic thresholds for imbalanced fraud detection (2% fraud rate)
  # Adjust based on your business requirements and class imbalance
  minimum_metrics:
    roc_auc: 0.65       # Minimum discriminative power
    precision: 0.03     # Accept low precision due to extreme imbalance
    recall: 0.30        # Prioritize catching fraud (minimize false negatives)

# Deployment Quality Gates
deployment:
  # Maximum allowed degradation vs production model (as percentage, e.g., 0.05 = 5%)
  degradation_tolerance:
    roc_auc: 0.05        # Allow up to 5% degradation in ROC-AUC
    precision: 0.05      # Allow up to 5% degradation in precision
    recall: 0.03         # Stricter: only 3% degradation in recall (critical for fraud)
    f1_score: 0.05       # Allow up to 5% degradation in F1
  
  # Critical metrics that must NOT degrade
  critical_metrics:
    - "recall"           # Fraud detection: missing fraud is costly
    - "roc_auc"          # Overall discriminative power
  
  # Baseline storage
  production_baseline_path: "data/production_model_baseline.json"

# Logging
logging:
  level: "INFO"
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
  file: "logs/training.log"
